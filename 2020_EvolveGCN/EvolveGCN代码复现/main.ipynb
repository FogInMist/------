{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as u\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "#datasets\n",
    "import bitcoin_dl as bc\n",
    "import elliptic_temporal_dl as ell_temp\n",
    "import uc_irv_mess_dl as ucim\n",
    "import auto_syst_dl as aus\n",
    "import sbm_dl as sbm\n",
    "import reddit_dl as rdt\n",
    "\n",
    "\n",
    "#taskers\n",
    "import link_pred_tasker as lpt\n",
    "import edge_cls_tasker as ect\n",
    "import node_cls_tasker as nct\n",
    "\n",
    "#models\n",
    "import models as mls\n",
    "import egcn_h\n",
    "import egcn_o\n",
    "\n",
    "\n",
    "import splitter as sp\n",
    "import Cross_Entropy as ce\n",
    "\n",
    "import trainer as tr\n",
    "\n",
    "import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = u.create_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.RawTextHelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\论文阅读记录\\2020_EvolveGCN\\EvolveGCN代码复现\\utils.py:139: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(args.config_file)\n"
     ]
    }
   ],
   "source": [
    "args = u.parse_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_loading_params = {'batch_size': 1, 'num_workers': 0}  # 调试方便使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model = 'egcn_h'  # 默认: egcn-O; egcn-H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(data='sbm50', sbm50_args={'folder': './data/', 'edges_file': 'sbm_50t_1000n_adj.csv', 'aggr_time': 1, 'feats_per_node': 3}, use_cuda=True, use_logfile=False, model='egcn_h', task='link_pred', class_weights=[0.1, 0.9], use_2_hot_node_feats=False, use_1_hot_node_feats=True, save_node_embeddings=False, train_proportion=0.7, dev_proportion=0.1, num_epochs=100, steps_accum_gradients=1, learning_rate=0.005, learning_rate_min=0.0001, learning_rate_max=0.1, negative_mult_training=50, negative_mult_test=100, smart_neg_sampling=True, seed=1234, target_measure='MAP', target_class=1, early_stop_patience=50, eval_after_epochs=5, adj_mat_time_window=1, num_hist_steps=5, num_hist_steps_min=1, num_hist_steps_max=10, data_loading_params={'batch_size': 1, 'num_workers': 0}, gcn_parameters={'feats_per_node': 100, 'feats_per_node_min': 50, 'feats_per_node_max': 256, 'layer_1_feats': 100, 'layer_1_feats_min': 10, 'layer_1_feats_max': 200, 'layer_2_feats': 100, 'layer_2_feats_same_as_l1': True, 'k_top_grcu': 200, 'num_layers': 2, 'lstm_l1_layers': 1, 'lstm_l1_feats': 100, 'lstm_l1_feats_min': 10, 'lstm_l1_feats_max': 200, 'lstm_l2_layers': 1, 'lstm_l2_feats': 100, 'lstm_l2_feats_same_as_l1': True, 'cls_feats': 100, 'cls_feats_min': 100, 'cls_feats_max': 800}, comments=['comments'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CUDA: True - device: cuda\n"
     ]
    }
   ],
   "source": [
    "global rank, wsize, use_cuda\n",
    "args.use_cuda = (torch.cuda.is_available() and args.use_cuda)\n",
    "args.device='cpu'\n",
    "if args.use_cuda:\n",
    "    args.device='cuda'\n",
    "print (\"use CUDA:\", args.use_cuda, \"- device:\", args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI backend not preset. Set process rank to 0 (out of 1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dist.init_process_group(backend='mpi') #, world_size=4\n",
    "    rank = dist.get_rank()\n",
    "    wsize = dist.get_world_size()\n",
    "    print('Hello from process {} (out of {})'.format(dist.get_rank(), dist.get_world_size()))\n",
    "    if args.use_cuda:\n",
    "        torch.cuda.set_device(rank )  # are we sure of the rank+1????\n",
    "        print('using the device {}'.format(torch.cuda.current_device()))\n",
    "except:\n",
    "    rank = 0\n",
    "    wsize = 1\n",
    "    print(('MPI backend not preset. Set process rank to {} (out of {})'.format(rank,\n",
    "                                                                                wsize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.seed is None and args.seed!='None':\n",
    "    seed = 123+rank#int(time.time())+rank\n",
    "else:\n",
    "    seed=args.seed  #+rank; 定义随机数\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "args.seed=seed\n",
    "args.rank=rank\n",
    "args.wsize=wsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_param_value(param, param_min, param_max, type='int'):\n",
    "\tif str(param) is None or str(param).lower()=='none':\n",
    "\t\tif type=='int':\n",
    "\t\t\treturn random.randrange(param_min, param_max+1)\n",
    "\t\telif type=='logscale':\n",
    "\t\t\tinterval=np.logspace(np.log10(param_min), np.log10(param_max), num=100)\n",
    "\t\t\treturn np.random.choice(interval,1)[0]\n",
    "\t\telse:\n",
    "\t\t\treturn random.uniform(param_min, param_max)\n",
    "\telse:\n",
    "\t\treturn param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_random_hyper_params(args):\n",
    "\tif args.model == 'all':\n",
    "\t\tmodel_types = ['gcn', 'egcn_o', 'egcn_h', 'gruA', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'all_nogcn':\n",
    "\t\tmodel_types = ['egcn_o', 'egcn_h', 'gruA', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'all_noegcn3':\n",
    "\t\tmodel_types = ['gcn', 'egcn_h', 'gruA', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'all_nogruA':\n",
    "\t\tmodel_types = ['gcn', 'egcn_o', 'egcn_h', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'saveembs':\n",
    "\t\tmodel_types = ['gcn', 'gcn', 'skipgcn', 'skipgcn']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "    # 设置learning rate\n",
    "\targs.learning_rate =random_param_value(args.learning_rate, args.learning_rate_min, args.learning_rate_max, type='logscale')\n",
    "\t# args.adj_mat_time_window = random_param_value(args.adj_mat_time_window, args.adj_mat_time_window_min, args.adj_mat_time_window_max, type='int')\n",
    "\n",
    "\tif args.model == 'gcn':\n",
    "\t\targs.num_hist_steps = 0\n",
    "\telse:  # 设置hist_steps\n",
    "\t\targs.num_hist_steps = random_param_value(args.num_hist_steps, args.num_hist_steps_min, args.num_hist_steps_max, type='int')\n",
    "\t# 设置feats_per_node\n",
    "\targs.gcn_parameters['feats_per_node'] =random_param_value(args.gcn_parameters['feats_per_node'], args.gcn_parameters['feats_per_node_min'], args.gcn_parameters['feats_per_node_max'], type='int')\n",
    "\targs.gcn_parameters['layer_1_feats'] =random_param_value(args.gcn_parameters['layer_1_feats'], args.gcn_parameters['layer_1_feats_min'], args.gcn_parameters['layer_1_feats_max'], type='int')\n",
    "\tif args.gcn_parameters['layer_2_feats_same_as_l1'] or args.gcn_parameters['layer_2_feats_same_as_l1'].lower()=='true':\n",
    "\t\targs.gcn_parameters['layer_2_feats'] = args.gcn_parameters['layer_1_feats']\n",
    "\telse:\n",
    "\t\targs.gcn_parameters['layer_2_feats'] =random_param_value(args.gcn_parameters['layer_2_feats'], args.gcn_parameters['layer_1_feats_min'], args.gcn_parameters['layer_1_feats_max'], type='int')\n",
    "\targs.gcn_parameters['lstm_l1_feats'] =random_param_value(args.gcn_parameters['lstm_l1_feats'], args.gcn_parameters['lstm_l1_feats_min'], args.gcn_parameters['lstm_l1_feats_max'], type='int')\n",
    "\tif args.gcn_parameters['lstm_l2_feats_same_as_l1'] or args.gcn_parameters['lstm_l2_feats_same_as_l1'].lower()=='true':\n",
    "\t\targs.gcn_parameters['lstm_l2_feats'] = args.gcn_parameters['lstm_l1_feats']\n",
    "\telse:\n",
    "\t\targs.gcn_parameters['lstm_l2_feats'] =random_param_value(args.gcn_parameters['lstm_l2_feats'], args.gcn_parameters['lstm_l1_feats_min'], args.gcn_parameters['lstm_l1_feats_max'], type='int')\n",
    "\targs.gcn_parameters['cls_feats']=random_param_value(args.gcn_parameters['cls_feats'], args.gcn_parameters['cls_feats_min'], args.gcn_parameters['cls_feats_max'], type='int')\n",
    "\treturn args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the requested random hyper parameters; 设置args\n",
    "args = build_random_hyper_params(args)  # 设置网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(data='sbm50', sbm50_args={'folder': './data/', 'edges_file': 'sbm_50t_1000n_adj.csv', 'aggr_time': 1, 'feats_per_node': 3}, use_cuda=True, use_logfile=False, model='egcn_h', task='link_pred', class_weights=[0.1, 0.9], use_2_hot_node_feats=False, use_1_hot_node_feats=True, save_node_embeddings=False, train_proportion=0.7, dev_proportion=0.1, num_epochs=100, steps_accum_gradients=1, learning_rate=0.005, learning_rate_min=0.0001, learning_rate_max=0.1, negative_mult_training=50, negative_mult_test=100, smart_neg_sampling=True, seed=1234, target_measure='MAP', target_class=1, early_stop_patience=50, eval_after_epochs=5, adj_mat_time_window=1, num_hist_steps=5, num_hist_steps_min=1, num_hist_steps_max=10, data_loading_params={'batch_size': 1, 'num_workers': 0}, gcn_parameters={'feats_per_node': 100, 'feats_per_node_min': 50, 'feats_per_node_max': 256, 'layer_1_feats': 100, 'layer_1_feats_min': 10, 'layer_1_feats_max': 200, 'layer_2_feats': 100, 'layer_2_feats_same_as_l1': True, 'k_top_grcu': 200, 'num_layers': 2, 'lstm_l1_layers': 1, 'lstm_l1_feats': 100, 'lstm_l1_feats_min': 10, 'lstm_l1_feats_max': 200, 'lstm_l2_layers': 1, 'lstm_l2_feats': 100, 'lstm_l2_feats_same_as_l1': True, 'cls_feats': 100, 'cls_feats_min': 100, 'cls_feats_max': 800}, comments=['comments'], device='cuda', rank=0, wsize=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(args):  # 数据集: 'sbm50'\n",
    "\tif args.data == 'bitcoinotc' or args.data == 'bitcoinalpha':\n",
    "\t\tif args.data == 'bitcoinotc':\n",
    "\t\t\targs.bitcoin_args = args.bitcoinotc_args\n",
    "\t\telif args.data == 'bitcoinalpha':\n",
    "\t\t\targs.bitcoin_args = args.bitcoinalpha_args\n",
    "\t\treturn bc.bitcoin_dataset(args)\n",
    "\telif args.data == 'aml_sim':\n",
    "\t\treturn aml.Aml_Dataset(args)\n",
    "\telif args.data == 'elliptic':\n",
    "\t\treturn ell.Elliptic_Dataset(args)\n",
    "\telif args.data == 'elliptic_temporal':\n",
    "\t\treturn ell_temp.Elliptic_Temporal_Dataset(args)\n",
    "\telif args.data == 'uc_irv_mess':\n",
    "\t\treturn ucim.Uc_Irvine_Message_Dataset(args)\n",
    "\telif args.data == 'dbg':\n",
    "\t\treturn dbg.dbg_dataset(args)\n",
    "\telif args.data == 'colored_graph':\n",
    "\t\treturn cg.Colored_Graph(args)\n",
    "\telif args.data == 'autonomous_syst':\n",
    "\t\treturn aus.Autonomous_Systems_Dataset(args)\n",
    "\telif args.data == 'reddit':\n",
    "\t\treturn rdt.Reddit_Dataset(args)\n",
    "\telif args.data.startswith('sbm'):\n",
    "\t\tif args.data == 'sbm20':\n",
    "\t\t\targs.sbm_args = args.sbm20_args\n",
    "\t\telif args.data == 'sbm50':\n",
    "\t\t\targs.sbm_args = args.sbm50_args  # 文件路径\n",
    "\t\treturn sbm.sbm_dataset(args)  # 读取数据\n",
    "\telse:\n",
    "\t\traise NotImplementedError('only arxiv has been implemented')\n",
    "\n",
    "def build_tasker(args,dataset):\n",
    "\tif args.task == 'link_pred':  # 边预测任务\n",
    "\t\treturn lpt.Link_Pred_Tasker(args,dataset)\n",
    "\telif args.task == 'edge_cls':\n",
    "\t\treturn ect.Edge_Cls_Tasker(args,dataset)\n",
    "\telif args.task == 'node_cls':\n",
    "\t\treturn nct.Node_Cls_Tasker(args,dataset)\n",
    "\telif args.task == 'static_node_cls':\n",
    "\t\treturn nct.Static_Node_Cls_Tasker(args,dataset)\n",
    "\n",
    "\telse:\n",
    "\t\traise NotImplementedError('still need to implement the other tasks')\n",
    "\n",
    "def build_gcn(args,tasker):\n",
    "\tgcn_args = u.Namespace(args.gcn_parameters)  # 模型参数\n",
    "\tgcn_args.feats_per_node = tasker.feats_per_node  # 节点最大的度; 构造one-hot特征\n",
    "\tif args.model == 'gcn':\n",
    "\t\treturn mls.Sp_GCN(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\telif args.model == 'skipgcn':\n",
    "\t\treturn mls.Sp_Skip_GCN(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\telif args.model == 'skipfeatsgcn':\n",
    "\t\treturn mls.Sp_Skip_NodeFeats_GCN(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\telse:\n",
    "\t\tassert args.num_hist_steps > 0, 'more than one step is necessary to train LSTM'\n",
    "\t\tif args.model == 'lstmA':\n",
    "\t\t\treturn mls.Sp_GCN_LSTM_A(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\telif args.model == 'gruA':\n",
    "\t\t\treturn mls.Sp_GCN_GRU_A(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\telif args.model == 'lstmB':\n",
    "\t\t\treturn mls.Sp_GCN_LSTM_B(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\telif args.model == 'gruB':\n",
    "\t\t\treturn mls.Sp_GCN_GRU_B(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\telif args.model == 'egcn':\n",
    "\t\t\treturn egcn.EGCN(gcn_args, activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\telif args.model == 'egcn_h':\n",
    "\t\t\treturn egcn_h.EGCN(gcn_args, activation = torch.nn.RReLU(), device = args.device)\n",
    "\t\telif args.model == 'skipfeatsegcn_h':\n",
    "\t\t\treturn egcn_h.EGCN(gcn_args, activation = torch.nn.RReLU(), device = args.device, skipfeats=True)\n",
    "\t\telif args.model == 'egcn_o':\n",
    "\t\t\treturn egcn_o.EGCN(gcn_args, activation = torch.nn.RReLU(), device = args.device)\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError('need to finish modifying the models')\n",
    "\n",
    "def build_classifier(args,tasker):\n",
    "\tif 'node_cls' == args.task or 'static_node_cls' == args.task:\n",
    "\t\tmult = 1\n",
    "\telse:\n",
    "\t\tmult = 2  # link_pred\n",
    "\tif 'gru' in args.model or 'lstm' in args.model:\n",
    "\t\tin_feats = args.gcn_parameters['lstm_l2_feats'] * mult\n",
    "\telif args.model == 'skipfeatsgcn' or args.model == 'skipfeatsegcn_h':\n",
    "\t\tin_feats = (args.gcn_parameters['layer_2_feats'] + args.gcn_parameters['feats_per_node']) * mult\n",
    "\telse:\n",
    "\t\tin_feats = args.gcn_parameters['layer_2_feats'] * mult  # EvolveGCN输出结果维度layer_2_feats * 2; link_pred所以*2\n",
    "\n",
    "\treturn mls.Classifier(args,in_features = in_feats, out_features = tasker.num_classes).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\论文阅读记录\\2020_EvolveGCN\\EvolveGCN代码复现\\utils.py:40: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  time_vector = time_vector // time_win_aggr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME tensor(49) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "dataset = build_dataset(args)  # 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sbm_dl.sbm_dataset at 0x2370525faf0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the tasker\n",
    "tasker = build_tasker(args,dataset)  # 预测任务link_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits sizes:  train 29 dev 5 test 10\n"
     ]
    }
   ],
   "source": [
    "# build the splitter\n",
    "splitter = sp.splitter(args,tasker)  # 训练，测试，验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS num_feats 200\n"
     ]
    }
   ],
   "source": [
    "# build the models\n",
    "gcn = build_gcn(args, tasker)\n",
    "classifier = build_classifier(args,tasker)  # link_pred分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a loss\n",
    "cross_entropy = ce.Cross_Entropy(args,dataset).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log: STDOUT\n",
      "INFO:root:*** PARAMETERS ***\n",
      "INFO:root:{'adj_mat_time_window': 1,\n",
      " 'class_weights': [0.1, 0.9],\n",
      " 'comments': ['comments'],\n",
      " 'data': 'sbm50',\n",
      " 'data_loading_params': {'batch_size': 1, 'num_workers': 0},\n",
      " 'dev_proportion': 0.1,\n",
      " 'device': 'cuda',\n",
      " 'early_stop_patience': 50,\n",
      " 'eval_after_epochs': 5,\n",
      " 'gcn_parameters': {'cls_feats': 100,\n",
      "                    'cls_feats_max': 800,\n",
      "                    'cls_feats_min': 100,\n",
      "                    'feats_per_node': 100,\n",
      "                    'feats_per_node_max': 256,\n",
      "                    'feats_per_node_min': 50,\n",
      "                    'k_top_grcu': 200,\n",
      "                    'layer_1_feats': 100,\n",
      "                    'layer_1_feats_max': 200,\n",
      "                    'layer_1_feats_min': 10,\n",
      "                    'layer_2_feats': 100,\n",
      "                    'layer_2_feats_same_as_l1': True,\n",
      "                    'lstm_l1_feats': 100,\n",
      "                    'lstm_l1_feats_max': 200,\n",
      "                    'lstm_l1_feats_min': 10,\n",
      "                    'lstm_l1_layers': 1,\n",
      "                    'lstm_l2_feats': 100,\n",
      "                    'lstm_l2_feats_same_as_l1': True,\n",
      "                    'lstm_l2_layers': 1,\n",
      "                    'num_layers': 2},\n",
      " 'learning_rate': 0.005,\n",
      " 'learning_rate_max': 0.1,\n",
      " 'learning_rate_min': 0.0001,\n",
      " 'model': 'egcn_h',\n",
      " 'negative_mult_test': 100,\n",
      " 'negative_mult_training': 50,\n",
      " 'num_epochs': 100,\n",
      " 'num_hist_steps': 5,\n",
      " 'num_hist_steps_max': 10,\n",
      " 'num_hist_steps_min': 1,\n",
      " 'rank': 0,\n",
      " 'save_node_embeddings': False,\n",
      " 'sbm50_args': {'aggr_time': 1,\n",
      "                'edges_file': 'sbm_50t_1000n_adj.csv',\n",
      "                'feats_per_node': 3,\n",
      "                'folder': './data/'},\n",
      " 'sbm_args': <utils.Namespace object at 0x000002370525FDF0>,\n",
      " 'seed': 1234,\n",
      " 'smart_neg_sampling': True,\n",
      " 'steps_accum_gradients': 1,\n",
      " 'target_class': 1,\n",
      " 'target_measure': 'MAP',\n",
      " 'task': 'link_pred',\n",
      " 'train_proportion': 0.7,\n",
      " 'use_1_hot_node_feats': True,\n",
      " 'use_2_hot_node_feats': False,\n",
      " 'use_cuda': True,\n",
      " 'use_logfile': False,\n",
      " 'wsize': 1}\n",
      "INFO:root:\n"
     ]
    }
   ],
   "source": [
    "# trainer\n",
    "trainer = tr.Trainer(args,\n",
    "                        splitter = splitter,  # 训练，测试，验证集\n",
    "                        gcn = gcn,  # Evolve_GCN模型\n",
    "                        classifier = classifier,  # link_pred 分类器\n",
    "                        comp_loss = cross_entropy,  # loss\n",
    "                        dataset = dataset,  # dataset\n",
    "                        num_classes = tasker.num_classes)  # 2分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:################ TRAIN epoch 0 ###################\n",
      "INFO:root:TRAIN mean losses tensor(0.1314, device='cuda:0')\n",
      "INFO:root:TRAIN mean errors 0.48084282875061035\n",
      "INFO:root:TRAIN mean MRR 0.0 - mean MAP 0.14682077535612448\n",
      "INFO:root:TRAIN tp {0: tensor(13464951, device='cuda:0'), 1: tensor(1575546, device='cuda:0')},fn {0: tensor(12670850, device='cuda:0'), 1: tensor(1259644, device='cuda:0')},fp {0: tensor(1259644, device='cuda:0'), 1: tensor(12670850, device='cuda:0')}\n",
      "INFO:root:TRAIN measures microavg - precision 0.5192 - recall 0.5192 - f1 0.5192 \n",
      "INFO:root:TRAIN measures for class 0 - precision 0.9145 - recall 0.5152 - f1 0.6591 \n",
      "INFO:root:TRAIN measures for class 1 - precision 0.1106 - recall 0.5557 - f1 0.1845 \n",
      "INFO:root:TRAIN measures@10 microavg - precision 0.4267 - recall 0.0000 - f1 0.0000 \n",
      "INFO:root:TRAIN measures@10 for class 0 - precision 0.6609 - recall 0.0000 - f1 0.0000 \n",
      "INFO:root:TRAIN measures@10 for class 1 - precision 0.1818 - recall 0.0000 - f1 0.0000 \n",
      "INFO:root:TRAIN measures@100 microavg - precision 0.4920 - recall 0.0001 - f1 0.0002 \n",
      "INFO:root:TRAIN measures@100 for class 0 - precision 0.7526 - recall 0.0001 - f1 0.0001 \n",
      "INFO:root:TRAIN measures@100 for class 1 - precision 0.2195 - recall 0.0002 - f1 0.0003 \n",
      "INFO:root:TRAIN measures@1000 microavg - precision 0.5197 - recall 0.0008 - f1 0.0016 \n",
      "INFO:root:TRAIN measures@1000 for class 0 - precision 0.7922 - recall 0.0007 - f1 0.0014 \n",
      "INFO:root:TRAIN measures@1000 for class 1 - precision 0.2349 - recall 0.0018 - f1 0.0036 \n",
      "INFO:root:TRAIN Total epoch time: 319.3289999999997\n",
      "INFO:root:################ TRAIN epoch 1 ###################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17672/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\论文阅读记录\\2020_EvolveGCN\\EvolveGCN代码复现\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                         \u001b[0meval_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes_embs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TRAIN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_after_epochs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                                 \u001b[0meval_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VALID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\论文阅读记录\\2020_EvolveGCN\\EvolveGCN代码复现\\trainer.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[1;34m(self, split, epoch, set_name, grad)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtasker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_static\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                                 \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_static_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\论文阅读记录\\2020_EvolveGCN\\EvolveGCN代码复现\\splitter.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0midx\u001b[0m  \u001b[1;31m# 额外增加5个时间步，预测下一个link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtasker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\论文阅读记录\\2020_EvolveGCN\\EvolveGCN代码复现\\link_pred_tasker.py\u001b[0m in \u001b[0;36mget_sample\u001b[1;34m(self, idx, test, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m                         \u001b[0mnon_exisiting_adj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_non_existing_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_adj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtot_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 负采样非自连接和已存在的边 {'idx', 'vals'}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m \t\t\tnon_exisiting_adj = tu.get_non_existing_edges(adj = label_adj,  # 下一个时间点的连接情况\n\u001b[0m\u001b[0;32m    155\u001b[0m                                                                                                           \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_adj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vals'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mneg_mult\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 负采样数量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m                                                                                                           \u001b[0mtot_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 节点数量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\论文阅读记录\\2020_EvolveGCN\\EvolveGCN代码复现\\taskers_utils.py\u001b[0m in \u001b[0;36mget_non_existing_edges\u001b[1;34m(adj, number, tot_nodes, smart_sampling, existing_nodes)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0msampled_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_edges\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 选择出不是自连接或者已经存在的边; 负采样\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0meid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 负采样样本;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[1;31m#ignore if any of these conditions happen; 1.负采样已经出现 2. 自连接 3. 正样本中已经存在的边\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mout_ids\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0medges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0medges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0meid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrue_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
