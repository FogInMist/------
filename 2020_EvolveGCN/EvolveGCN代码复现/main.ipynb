{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EvolveGCN代码复现\n",
    "\n",
    "* [源仓库地址](https://github.com/IBM/EvolveGCN)\n",
    "\n",
    "**注意：**\n",
    "\n",
    "由于使用了jupyter notebook来运行代码，部分python文件进行了相应改动。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  导入python文件和相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as u\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "#datasets\n",
    "import bitcoin_dl as bc\n",
    "import elliptic_temporal_dl as ell_temp\n",
    "import uc_irv_mess_dl as ucim\n",
    "import auto_syst_dl as aus\n",
    "import sbm_dl as sbm\n",
    "import reddit_dl as rdt\n",
    "\n",
    "\n",
    "#taskers\n",
    "import link_pred_tasker as lpt\n",
    "import edge_cls_tasker as ect\n",
    "import node_cls_tasker as nct\n",
    "\n",
    "#models\n",
    "import models as mls\n",
    "import egcn_h\n",
    "import egcn_o\n",
    "\n",
    "\n",
    "import splitter as sp\n",
    "import Cross_Entropy as ce\n",
    "\n",
    "import trainer as tr\n",
    "\n",
    "import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全局参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = u.create_parser() # 创建参数解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.RawTextHelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='experiments/parameters_example.yaml' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "args = u.parse_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_loading_params = {'batch_size': 1, 'num_workers': 0}  # 方便单计算机调试使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model = 'egcn_o'  # 默认: egcn-O; egcn-H  # 采用的模型类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数可视化制表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from texttable import Texttable\n",
    "\n",
    "def tab_printer(args):\n",
    "    args = vars(args)\n",
    "    keys = sorted(args.keys())\n",
    "    t = Texttable()\n",
    "    rows = [[\"Parameter\", \"Value\"]]\n",
    "    for i in [[k.replace(\"_\", \" \").capitalize(), args[k]] for k in keys]:\n",
    "        rows.append(i)\n",
    "    # print(rows)\n",
    "    t.add_rows(rows)\n",
    "    print(t.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------------------------------------+\n",
      "|       Parameter        |                        Value                        |\n",
      "+========================+=====================================================+\n",
      "| Adj mat time window    | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Class weights          | [0.1, 0.9]                                          |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Comments               | ['comments']                                        |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Data                   | sbm50                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Data loading params    | {'batch_size': 1, 'num_workers': 0}                 |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Dev proportion         | 0.100                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Early stop patience    | 50                                                  |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Eval after epochs      | 5                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Gcn parameters         | {'feats_per_node': 100, 'feats_per_node_min': 50,   |\n",
      "|                        | 'feats_per_node_max': 256, 'layer_1_feats': 100,    |\n",
      "|                        | 'layer_1_feats_min': 10, 'layer_1_feats_max': 200,  |\n",
      "|                        | 'layer_2_feats': 100, 'layer_2_feats_same_as_l1':   |\n",
      "|                        | True, 'k_top_grcu': 200, 'num_layers': 2,           |\n",
      "|                        | 'lstm_l1_layers': 1, 'lstm_l1_feats': 100,          |\n",
      "|                        | 'lstm_l1_feats_min': 10, 'lstm_l1_feats_max': 200,  |\n",
      "|                        | 'lstm_l2_layers': 1, 'lstm_l2_feats': 100,          |\n",
      "|                        | 'lstm_l2_feats_same_as_l1': True, 'cls_feats': 100, |\n",
      "|                        | 'cls_feats_min': 100, 'cls_feats_max': 800}         |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Learning rate          | 0.005                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Learning rate max      | 0.100                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Learning rate min      | 0.000                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Model                  | egcn_o                                              |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Negative mult test     | 100                                                 |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Negative mult training | 50                                                  |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Num epochs             | 2                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Num hist steps         | 5                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Num hist steps max     | 10                                                  |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Num hist steps min     | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Save node embeddings   | 0                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Sbm50 args             | {'folder': './data/', 'edges_file':                 |\n",
      "|                        | 'sbm_50t_1000n_adj.csv', 'aggr_time': 1,            |\n",
      "|                        | 'feats_per_node': 3}                                |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Seed                   | 1234                                                |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Smart neg sampling     | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Steps accum gradients  | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Target class           | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Target measure         | MAP                                                 |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Task                   | link_pred                                           |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Train proportion       | 0.700                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Use 1 hot node feats   | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Use 2 hot node feats   | 0                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Use cuda               | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Use logfile            | 0                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "tab_printer(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理器定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CUDA: False - device: cpu\n"
     ]
    }
   ],
   "source": [
    "global rank, wsize, use_cuda\n",
    "args.use_cuda = (torch.cuda.is_available() and args.use_cuda)\n",
    "args.device='cpu'\n",
    "if args.use_cuda:\n",
    "    args.device='cuda'\n",
    "print (\"use CUDA:\", args.use_cuda, \"- device:\", args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判断是否处于分布式环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI backend not preset. Set process rank to 0 (out of 1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dist.init_process_group(backend='mpi') #, world_size=4\n",
    "    rank = dist.get_rank()\n",
    "    wsize = dist.get_world_size()\n",
    "    print('Hello from process {} (out of {})'.format(dist.get_rank(), dist.get_world_size()))\n",
    "    if args.use_cuda:\n",
    "        torch.cuda.set_device(rank)  # are we sure of the rank+1????\n",
    "        print('using the device {}'.format(torch.cuda.current_device()))\n",
    "except:\n",
    "    rank = 0\n",
    "    wsize = 1\n",
    "    print(('MPI backend not preset. Set process rank to {} (out of {})'.format(rank,\n",
    "                                                                                wsize)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后端分布式进程组名为“mpi”, 但MPI后端并未预先设置,所以需要将进程rank设置为0,  world_size设置为1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with seed: 1234\n",
      "seed: 1234 ; rank: 0 ; wsize: 1\n"
     ]
    }
   ],
   "source": [
    "if args.seed is None and args.seed!='None':\n",
    "    seed = 123+rank #int(time.time())+rank\n",
    "else:\n",
    "    seed = args.seed  #+rank; 定义随机数\n",
    "print(('Running with seed: {}'.format(seed)))\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "args.seed=seed\n",
    "args.rank=rank\n",
    "args.wsize=wsize\n",
    "print('seed:', args.seed, '; rank:',args.rank, '; wsize:',args.wsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_param_value(param, param_min, param_max, type='int'):\n",
    "\tif str(param) is None or str(param).lower()=='none':\n",
    "\t\tif type=='int':\n",
    "\t\t\treturn random.randrange(param_min, param_max+1)\n",
    "\t\telif type=='logscale':\n",
    "\t\t\tinterval=np.logspace(np.log10(param_min), np.log10(param_max), num=100)\n",
    "\t\t\treturn np.random.choice(interval,1)[0]\n",
    "\t\telse:\n",
    "\t\t\treturn random.uniform(param_min, param_max)\n",
    "\telse:\n",
    "\t\treturn param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_random_hyper_params(args):\n",
    "\t# 网络模型选择\n",
    "\tif args.model == 'all':\n",
    "\t\tmodel_types = ['gcn', 'egcn_o', 'egcn_h', 'gruA', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'all_nogcn':\n",
    "\t\tmodel_types = ['egcn_o', 'egcn_h', 'gruA', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'all_noegcn3':\n",
    "\t\tmodel_types = ['gcn', 'egcn_h', 'gruA', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'all_nogruA':\n",
    "\t\tmodel_types = ['gcn', 'egcn_o', 'egcn_h', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'saveembs':\n",
    "\t\tmodel_types = ['gcn', 'gcn', 'skipgcn', 'skipgcn']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "    \n",
    "\t# 设置learning rate\n",
    "\targs.learning_rate =random_param_value(args.learning_rate, args.learning_rate_min, args.learning_rate_max, type='logscale')\n",
    "\t# args.adj_mat_time_window = random_param_value(args.adj_mat_time_window, args.adj_mat_time_window_min, args.adj_mat_time_window_max, type='int')\n",
    "\n",
    "\tif args.model == 'gcn':\n",
    "\t\targs.num_hist_steps = 0\n",
    "\telse:  # 设置hist_steps\n",
    "\t\targs.num_hist_steps = random_param_value(args.num_hist_steps, args.num_hist_steps_min, args.num_hist_steps_max, type='int')\n",
    "\t\n",
    "\t# 设置feats_per_node\n",
    "\targs.gcn_parameters['feats_per_node'] =random_param_value(args.gcn_parameters['feats_per_node'], args.gcn_parameters['feats_per_node_min'], args.gcn_parameters['feats_per_node_max'], type='int')\n",
    "\targs.gcn_parameters['layer_1_feats'] =random_param_value(args.gcn_parameters['layer_1_feats'], args.gcn_parameters['layer_1_feats_min'], args.gcn_parameters['layer_1_feats_max'], type='int')\n",
    "\tif args.gcn_parameters['layer_2_feats_same_as_l1'] or args.gcn_parameters['layer_2_feats_same_as_l1'].lower()=='true':\n",
    "\t\targs.gcn_parameters['layer_2_feats'] = args.gcn_parameters['layer_1_feats']\n",
    "\telse:\n",
    "\t\targs.gcn_parameters['layer_2_feats'] =random_param_value(args.gcn_parameters['layer_2_feats'], args.gcn_parameters['layer_1_feats_min'], args.gcn_parameters['layer_1_feats_max'], type='int')\n",
    "\targs.gcn_parameters['lstm_l1_feats'] =random_param_value(args.gcn_parameters['lstm_l1_feats'], args.gcn_parameters['lstm_l1_feats_min'], args.gcn_parameters['lstm_l1_feats_max'], type='int')\n",
    "\tif args.gcn_parameters['lstm_l2_feats_same_as_l1'] or args.gcn_parameters['lstm_l2_feats_same_as_l1'].lower()=='true':\n",
    "\t\targs.gcn_parameters['lstm_l2_feats'] = args.gcn_parameters['lstm_l1_feats']\n",
    "\telse:\n",
    "\t\targs.gcn_parameters['lstm_l2_feats'] =random_param_value(args.gcn_parameters['lstm_l2_feats'], args.gcn_parameters['lstm_l1_feats_min'], args.gcn_parameters['lstm_l1_feats_max'], type='int')\n",
    "\targs.gcn_parameters['cls_feats']=random_param_value(args.gcn_parameters['cls_feats'], args.gcn_parameters['cls_feats_min'], args.gcn_parameters['cls_feats_max'], type='int')\n",
    "\t\n",
    "\treturn args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the requested random hyper parameters; 设置args\n",
    "args = build_random_hyper_params(args)  # 设置网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------------------------------------+\n",
      "|       Parameter        |                        Value                        |\n",
      "+========================+=====================================================+\n",
      "| Adj mat time window    | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Class weights          | [0.1, 0.9]                                          |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Comments               | ['comments']                                        |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Data                   | sbm50                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Data loading params    | {'batch_size': 1, 'num_workers': 0}                 |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Dev proportion         | 0.100                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Device                 | cpu                                                 |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Early stop patience    | 50                                                  |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Eval after epochs      | 5                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Gcn parameters         | {'feats_per_node': 100, 'feats_per_node_min': 50,   |\n",
      "|                        | 'feats_per_node_max': 256, 'layer_1_feats': 100,    |\n",
      "|                        | 'layer_1_feats_min': 10, 'layer_1_feats_max': 200,  |\n",
      "|                        | 'layer_2_feats': 100, 'layer_2_feats_same_as_l1':   |\n",
      "|                        | True, 'k_top_grcu': 200, 'num_layers': 2,           |\n",
      "|                        | 'lstm_l1_layers': 1, 'lstm_l1_feats': 100,          |\n",
      "|                        | 'lstm_l1_feats_min': 10, 'lstm_l1_feats_max': 200,  |\n",
      "|                        | 'lstm_l2_layers': 1, 'lstm_l2_feats': 100,          |\n",
      "|                        | 'lstm_l2_feats_same_as_l1': True, 'cls_feats': 100, |\n",
      "|                        | 'cls_feats_min': 100, 'cls_feats_max': 800}         |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Learning rate          | 0.005                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Learning rate max      | 0.100                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Learning rate min      | 0.000                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Model                  | egcn_o                                              |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Negative mult test     | 100                                                 |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Negative mult training | 50                                                  |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Num epochs             | 2                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Num hist steps         | 5                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Num hist steps max     | 10                                                  |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Num hist steps min     | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Rank                   | 0                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Save node embeddings   | 0                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Sbm50 args             | {'folder': './data/', 'edges_file':                 |\n",
      "|                        | 'sbm_50t_1000n_adj.csv', 'aggr_time': 1,            |\n",
      "|                        | 'feats_per_node': 3}                                |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Seed                   | 1234                                                |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Smart neg sampling     | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Steps accum gradients  | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Target class           | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Target measure         | MAP                                                 |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Task                   | link_pred                                           |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Train proportion       | 0.700                                               |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Use 1 hot node feats   | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Use 2 hot node feats   | 0                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Use cuda               | 0                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Use logfile            | 0                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n",
      "| Wsize                  | 1                                                   |\n",
      "+------------------------+-----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "tab_printer(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(args):  # 数据集: 'sbm50'\n",
    "\tif args.data == 'bitcoinotc' or args.data == 'bitcoinalpha':\n",
    "\t\tif args.data == 'bitcoinotc':\n",
    "\t\t\targs.bitcoin_args = args.bitcoinotc_args\n",
    "\t\telif args.data == 'bitcoinalpha':\n",
    "\t\t\targs.bitcoin_args = args.bitcoinalpha_args\n",
    "\t\treturn bc.bitcoin_dataset(args)\n",
    "\t# elif args.data == 'aml_sim':\n",
    "\t# \treturn aml.Aml_Dataset(args)\n",
    "\t# elif args.data == 'elliptic':\n",
    "\t# \treturn ell.Elliptic_Dataset(args)\n",
    "\t# elif args.data == 'elliptic_temporal':\n",
    "\t# \treturn ell_temp.Elliptic_Temporal_Dataset(args)\n",
    "\t# elif args.data == 'uc_irv_mess':\n",
    "\t# \treturn ucim.Uc_Irvine_Message_Dataset(args)\n",
    "\t# elif args.data == 'dbg':\n",
    "\t# \treturn dbg.dbg_dataset(args)\n",
    "\t# elif args.data == 'colored_graph':\n",
    "\t# \treturn cg.Colored_Graph(args)\n",
    "\t# elif args.data == 'autonomous_syst':\n",
    "\t# \treturn aus.Autonomous_Systems_Dataset(args)\n",
    "\t# elif args.data == 'reddit':\n",
    "\t# \treturn rdt.Reddit_Dataset(args)\n",
    "\telif args.data.startswith('sbm'):\n",
    "\t\tif args.data == 'sbm20':\n",
    "\t\t\targs.sbm_args = args.sbm20_args\n",
    "\t\telif args.data == 'sbm50':\n",
    "\t\t\targs.sbm_args = args.sbm50_args  # 文件路径\n",
    "\t\t\tprint(args.sbm_args)\n",
    "\t\treturn sbm.sbm_dataset(args)  # 读取数据\n",
    "\t\n",
    "\telse:\n",
    "\t\traise NotImplementedError('only arxiv has been implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'folder': './data/', 'edges_file': 'sbm_50t_1000n_adj.csv', 'aggr_time': 1, 'feats_per_node': 3}\n",
      "max_time: tensor(49)\n",
      "min_time: tensor(0)\n",
      "num_nodes: 1000\n",
      "num_non_existing: -3870863\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# build the dataset\n",
    "dataset = build_dataset(args)  # 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': tensor([[  0,   2,   0],\n",
       "         [  0,   3,   0],\n",
       "         [  0,   8,   0],\n",
       "         ...,\n",
       "         [999, 959,  49],\n",
       "         [999, 970,  49],\n",
       "         [999, 991,  49]]),\n",
       " 'vals': tensor([1, 1, 1,  ..., 1, 1, 1])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建任务类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tasker(args,dataset):\n",
    "\tif args.task == 'link_pred':  # 边预测任务\n",
    "\t\treturn lpt.Link_Pred_Tasker(args,dataset)\n",
    "\telif args.task == 'edge_cls':\n",
    "\t\treturn ect.Edge_Cls_Tasker(args,dataset)\n",
    "\telif args.task == 'node_cls':\n",
    "\t\treturn nct.Node_Cls_Tasker(args,dataset)\n",
    "\telif args.task == 'static_node_cls':\n",
    "\t\treturn nct.Static_Node_Cls_Tasker(args,dataset)\n",
    "\n",
    "\telse:\n",
    "\t\traise NotImplementedError('still need to implement the other tasks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the tasker\n",
    "tasker = build_tasker(args, dataset)  # 预测任务link_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练，测试，验证集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits sizes:  train 29 dev 5 test 10\n"
     ]
    }
   ],
   "source": [
    "# build the splitter\n",
    "splitter = sp.splitter(args,tasker)  # 训练，测试，验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.train.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gcn(args,tasker):\n",
    "\tgcn_args = u.Namespace(args.gcn_parameters)  # 模型参数\n",
    "\tgcn_args.feats_per_node = tasker.feats_per_node  # 节点最大的度; 构造one-hot特征\n",
    "\tprint('feats_per_node:',gcn_args.feats_per_node)\n",
    "\tif args.model == 'gcn':\n",
    "\t\treturn mls.Sp_GCN(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t# elif args.model == 'skipgcn':\n",
    "\t# \treturn mls.Sp_Skip_GCN(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t# elif args.model == 'skipfeatsgcn':\n",
    "\t# \treturn mls.Sp_Skip_NodeFeats_GCN(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\telse:\n",
    "\t\tassert args.num_hist_steps > 0, 'more than one step is necessary to train LSTM'\n",
    "\t\tif args.model == 'lstmA':\n",
    "\t\t\treturn mls.Sp_GCN_LSTM_A(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\t# elif args.model == 'gruA':\n",
    "\t\t# \treturn mls.Sp_GCN_GRU_A(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\t# elif args.model == 'lstmB':\n",
    "\t\t# \treturn mls.Sp_GCN_LSTM_B(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\t# elif args.model == 'gruB':\n",
    "\t\t# \treturn mls.Sp_GCN_GRU_B(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\t# elif args.model == 'egcn':\n",
    "\t\t# \treturn egcn.EGCN(gcn_args, activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\telif args.model == 'egcn_h':\n",
    "\t\t\treturn egcn_h.EGCN(gcn_args, activation = torch.nn.RReLU(), device = args.device)\n",
    "\t\t# elif args.model == 'skipfeatsegcn_h':\n",
    "\t\t# \treturn egcn_h.EGCN(gcn_args, activation = torch.nn.RReLU(), device = args.device, skipfeats=True)\n",
    "\t\telif args.model == 'egcn_o':\n",
    "\t\t\treturn egcn_o.EGCN(gcn_args, activation = torch.nn.RReLU(), device = args.device)\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError('need to finish modifying the models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_per_node: 162\n"
     ]
    }
   ],
   "source": [
    "# build the models\n",
    "gcn = build_gcn(args, tasker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建分类器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(args,tasker):\n",
    "\tif 'node_cls' == args.task or 'static_node_cls' == args.task:\n",
    "\t\tmult = 1\n",
    "\telse:\n",
    "\t\tmult = 2  # link_pred\n",
    "\tif 'gru' in args.model or 'lstm' in args.model:\n",
    "\t\tin_feats = args.gcn_parameters['lstm_l2_feats'] * mult\n",
    "\telif args.model == 'skipfeatsgcn' or args.model == 'skipfeatsegcn_h':\n",
    "\t\tin_feats = (args.gcn_parameters['layer_2_feats'] + args.gcn_parameters['feats_per_node']) * mult\n",
    "\telse:\n",
    "\t\tin_feats = args.gcn_parameters['layer_2_feats'] * mult  # EvolveGCN输出结果维度layer_2_feats * 2; link_pred所以*2\n",
    "\n",
    "\treturn mls.Classifier(args,in_features = in_feats, out_features = tasker.num_classes).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS num_feats 200\n"
     ]
    }
   ],
   "source": [
    "classifier = build_classifier(args,tasker)  # link_pred分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a loss\n",
    "cross_entropy = ce.Cross_Entropy(args, dataset).to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log: STDOUT\n",
      "INFO:root:*** PARAMETERS ***\n",
      "INFO:root:{'adj_mat_time_window': 1,\n",
      " 'class_weights': [0.1, 0.9],\n",
      " 'comments': ['comments'],\n",
      " 'data': 'sbm50',\n",
      " 'data_loading_params': {'batch_size': 1, 'num_workers': 0},\n",
      " 'dev_proportion': 0.1,\n",
      " 'device': 'cpu',\n",
      " 'early_stop_patience': 50,\n",
      " 'eval_after_epochs': 5,\n",
      " 'gcn_parameters': {'cls_feats': 100,\n",
      "                    'cls_feats_max': 800,\n",
      "                    'cls_feats_min': 100,\n",
      "                    'feats_per_node': 100,\n",
      "                    'feats_per_node_max': 256,\n",
      "                    'feats_per_node_min': 50,\n",
      "                    'k_top_grcu': 200,\n",
      "                    'layer_1_feats': 100,\n",
      "                    'layer_1_feats_max': 200,\n",
      "                    'layer_1_feats_min': 10,\n",
      "                    'layer_2_feats': 100,\n",
      "                    'layer_2_feats_same_as_l1': True,\n",
      "                    'lstm_l1_feats': 100,\n",
      "                    'lstm_l1_feats_max': 200,\n",
      "                    'lstm_l1_feats_min': 10,\n",
      "                    'lstm_l1_layers': 1,\n",
      "                    'lstm_l2_feats': 100,\n",
      "                    'lstm_l2_feats_same_as_l1': True,\n",
      "                    'lstm_l2_layers': 1,\n",
      "                    'num_layers': 2},\n",
      " 'learning_rate': 0.005,\n",
      " 'learning_rate_max': 0.1,\n",
      " 'learning_rate_min': 0.0001,\n",
      " 'model': 'egcn_o',\n",
      " 'negative_mult_test': 100,\n",
      " 'negative_mult_training': 50,\n",
      " 'num_epochs': 2,\n",
      " 'num_hist_steps': 5,\n",
      " 'num_hist_steps_max': 10,\n",
      " 'num_hist_steps_min': 1,\n",
      " 'rank': 0,\n",
      " 'save_node_embeddings': False,\n",
      " 'sbm50_args': {'aggr_time': 1,\n",
      "                'edges_file': 'sbm_50t_1000n_adj.csv',\n",
      "                'feats_per_node': 3,\n",
      "                'folder': './data/'},\n",
      " 'sbm_args': <utils.Namespace object at 0x0000014D99C70F70>,\n",
      " 'seed': 1234,\n",
      " 'smart_neg_sampling': True,\n",
      " 'steps_accum_gradients': 1,\n",
      " 'target_class': 1,\n",
      " 'target_measure': 'MAP',\n",
      " 'task': 'link_pred',\n",
      " 'train_proportion': 0.7,\n",
      " 'use_1_hot_node_feats': True,\n",
      " 'use_2_hot_node_feats': False,\n",
      " 'use_cuda': False,\n",
      " 'use_logfile': False,\n",
      " 'wsize': 1}\n",
      "INFO:root:\n"
     ]
    }
   ],
   "source": [
    "# trainer\n",
    "trainer = tr.Trainer(args,\n",
    "                        splitter = splitter,  # 训练，测试，验证集\n",
    "                        gcn = gcn,  # Evolve_GCN模型\n",
    "                        classifier = classifier,  # link_pred 分类器\n",
    "                        comp_loss = cross_entropy,  # loss\n",
    "                        dataset = dataset,  # dataset\n",
    "                        num_classes = tasker.num_classes)  # 2分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:################ TRAIN epoch 0 ###################\n",
      "INFO:root:TRAIN mean losses tensor(0.1249)\n",
      "INFO:root:TRAIN mean errors 0.19567318260669708\n",
      "INFO:root:TRAIN mean MRR 0.0 - mean MAP 0.15319414805181736\n",
      "INFO:root:TRAIN tp {0: tensor(22879027), 1: tensor(423118)},fn {0: tensor(3256774), 1: tensor(2412072)},fp {0: tensor(2412072), 1: tensor(3256774)}\n",
      "INFO:root:TRAIN measures microavg - precision 0.8043 - recall 0.8043 - f1 0.8043 \n",
      "INFO:root:TRAIN measures for class 0 - precision 0.9046 - recall 0.8754 - f1 0.8898 \n",
      "INFO:root:TRAIN measures for class 1 - precision 0.1150 - recall 0.1492 - f1 0.1299 \n",
      "INFO:root:TRAIN measures@10 microavg - precision 0.7094 - recall 0.0000 - f1 0.0000 \n",
      "INFO:root:TRAIN measures@10 for class 0 - precision 0.7778 - recall 0.0000 - f1 0.0000 \n",
      "INFO:root:TRAIN measures@10 for class 1 - precision 0.3400 - recall 0.0000 - f1 0.0000 \n",
      "INFO:root:TRAIN measures@100 microavg - precision 0.6781 - recall 0.0001 - f1 0.0001 \n",
      "INFO:root:TRAIN measures@100 for class 0 - precision 0.7585 - recall 0.0001 - f1 0.0002 \n",
      "INFO:root:TRAIN measures@100 for class 1 - precision 0.2440 - recall 0.0000 - f1 0.0001 \n",
      "INFO:root:TRAIN measures@1000 microavg - precision 0.7002 - recall 0.0008 - f1 0.0015 \n",
      "INFO:root:TRAIN measures@1000 for class 0 - precision 0.7840 - recall 0.0008 - f1 0.0016 \n",
      "INFO:root:TRAIN measures@1000 for class 1 - precision 0.2480 - recall 0.0004 - f1 0.0009 \n",
      "INFO:root:TRAIN Total epoch time: 312.09399999992456\n",
      "INFO:root:################ TRAIN epoch 1 ###################\n",
      "INFO:root:TRAIN mean losses tensor(0.1089)\n",
      "INFO:root:TRAIN mean errors 0.41922861337661743\n",
      "INFO:root:TRAIN mean MRR 0.0 - mean MAP 0.18166290976274854\n",
      "INFO:root:TRAIN tp {0: tensor(14572226), 1: tensor(2253292)},fn {0: tensor(11563569), 1: tensor(581898)},fp {0: tensor(581898), 1: tensor(11563569)}\n",
      "INFO:root:TRAIN measures microavg - precision 0.5808 - recall 0.5808 - f1 0.5808 \n",
      "INFO:root:TRAIN measures for class 0 - precision 0.9616 - recall 0.5576 - f1 0.7058 \n",
      "INFO:root:TRAIN measures for class 1 - precision 0.1631 - recall 0.7948 - f1 0.2706 \n",
      "INFO:root:TRAIN measures@10 microavg - precision 0.5809 - recall 0.0000 - f1 0.0000 \n",
      "INFO:root:TRAIN measures@10 for class 0 - precision 0.9448 - recall 0.0000 - f1 0.0000 \n",
      "INFO:root:TRAIN measures@10 for class 1 - precision 0.2105 - recall 0.0000 - f1 0.0000 \n",
      "INFO:root:TRAIN measures@100 microavg - precision 0.5881 - recall 0.0001 - f1 0.0002 \n",
      "INFO:root:TRAIN measures@100 for class 0 - precision 0.9431 - recall 0.0001 - f1 0.0002 \n",
      "INFO:root:TRAIN measures@100 for class 1 - precision 0.2323 - recall 0.0002 - f1 0.0005 \n",
      "INFO:root:TRAIN measures@1000 microavg - precision 0.5922 - recall 0.0012 - f1 0.0024 \n",
      "INFO:root:TRAIN measures@1000 for class 0 - precision 0.9393 - recall 0.0010 - f1 0.0021 \n",
      "INFO:root:TRAIN measures@1000 for class 1 - precision 0.2450 - recall 0.0025 - f1 0.0050 \n",
      "INFO:root:TRAIN Total epoch time: 313.89000000001397\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
