{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model import GTN\n",
    "import pdb\n",
    "import pickle\n",
    "import argparse\n",
    "from utils import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='DBLP', epoch=40, node_dim=64, num_channels=2, lr=0.005, weight_decay=0.001, num_layers=2, norm='true', adaptive_lr='false')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type=str, default='DBLP',\n",
    "                    help='Dataset')\n",
    "parser.add_argument('--epoch', type=int, default=40,\n",
    "                    help='Training Epochs')\n",
    "parser.add_argument('--node_dim', type=int, default=64,\n",
    "                    help='Node dimension')\n",
    "parser.add_argument('--num_channels', type=int, default=2,\n",
    "                    help='number of channels')\n",
    "parser.add_argument('--lr', type=float, default=0.005,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.001,\n",
    "                    help='l2 reg')\n",
    "parser.add_argument('--num_layers', type=int, default=2,\n",
    "                    help='number of layer')\n",
    "parser.add_argument('--norm', type=str, default='true',\n",
    "                    help='normalization')\n",
    "parser.add_argument('--adaptive_lr', type=str, default='false',\n",
    "                    help='adaptive learning rate')\n",
    "\n",
    "#args = parser.parse_args()                                               # pychram 中使用\n",
    "args = parser.parse_known_args()[0]                                       # jupyter 中使用\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = args.epoch\n",
    "node_dim = args.node_dim\n",
    "num_channels = args.num_channels\n",
    "lr = args.lr\n",
    "weight_decay = args.weight_decay\n",
    "num_layers = args.num_layers\n",
    "norm = args.norm\n",
    "adaptive_lr = args.adaptive_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "with open('../data/'+args.dataset+'/node_features.pkl','rb') as f:\n",
    "    node_features = pickle.load(f)\n",
    "with open('../data/'+args.dataset+'/edges.pkl','rb') as f:\n",
    "    edges = pickle.load(f)\n",
    "with open('../data/'+args.dataset+'/labels.pkl','rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "num_nodes = edges[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,edge in enumerate(edges):\n",
    "    if i ==0:\n",
    "        A = torch.from_numpy(edge.todense()).type(torch.FloatTensor).unsqueeze(-1)\n",
    "    else:\n",
    "        A = torch.cat([A,torch.from_numpy(edge.todense()).type(torch.FloatTensor).unsqueeze(-1)], dim=-1)\n",
    "A = torch.cat([A,torch.eye(num_nodes).type(torch.FloatTensor).unsqueeze(-1)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18405, 18405, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = torch.from_numpy(node_features).type(torch.FloatTensor)\n",
    "train_node = torch.from_numpy(np.array(labels[0])[:,0]).type(torch.LongTensor)\n",
    "train_target = torch.from_numpy(np.array(labels[0])[:,1]).type(torch.LongTensor)\n",
    "valid_node = torch.from_numpy(np.array(labels[1])[:,0]).type(torch.LongTensor)\n",
    "valid_target = torch.from_numpy(np.array(labels[1])[:,1]).type(torch.LongTensor)\n",
    "test_node = torch.from_numpy(np.array(labels[2])[:,0]).type(torch.LongTensor)\n",
    "test_target = torch.from_numpy(np.array(labels[2])[:,1]).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18405, 334])\n",
      "torch.Size([800])\n",
      "torch.Size([800])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([2857])\n",
      "torch.Size([2857])\n",
      "torch.Size([18405, 18405, 5])\n"
     ]
    }
   ],
   "source": [
    "print(node_features.shape)\n",
    "print(train_node.shape)\n",
    "print(train_target.shape)\n",
    "print(valid_node.shape)\n",
    "print(valid_target.shape)\n",
    "print(test_node.shape)\n",
    "print(test_target.shape)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = torch.max(train_target).item()+1\n",
    "final_f1 = 0\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1\n",
      "Train - Loss: 1.390804409980774, Macro_F1: 0.11158082634210587\n",
      "Valid - Loss: 1.3697787523269653, Macro_F1: 0.2811485528945923\n",
      "Test - Loss: 1.3840534687042236, Macro_F1: 0.24715301394462585\n",
      "\n",
      "---------------Best Results--------------------\n",
      "Train - Loss: 1.390804409980774, Macro_F1: 0.11158082634210587\n",
      "Valid - Loss: 1.3697787523269653, Macro_F1: 0.2811485528945923\n",
      "Test - Loss: 1.3840534687042236, Macro_F1: 0.24715301394462585\n"
     ]
    }
   ],
   "source": [
    "for l in range(1):\n",
    "    model = GTN(num_edge=A.shape[-1],\n",
    "                        num_channels=num_channels,\n",
    "                        w_in = node_features.shape[1],\n",
    "                        w_out = node_dim,\n",
    "                        num_class=num_classes,\n",
    "                        num_layers=num_layers,\n",
    "                        norm=norm)\n",
    "    if adaptive_lr == 'false':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam([{'params':model.weight},\n",
    "                                    {'params':model.linear1.parameters()},\n",
    "                                    {'params':model.linear2.parameters()},\n",
    "                                    {\"params\":model.layers.parameters(), \"lr\":0.5}\n",
    "                                    ], lr=0.005, weight_decay=0.001)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    # Train & Valid & Test\n",
    "    best_val_loss = 10000\n",
    "    best_test_loss = 10000\n",
    "    best_train_loss = 10000\n",
    "    best_train_f1 = 0\n",
    "    best_val_f1 = 0\n",
    "    best_test_f1 = 0\n",
    "    \n",
    "    # for i in range(epochs):\n",
    "    for i in range(1):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            if param_group['lr'] > 0.005:\n",
    "                param_group['lr'] = param_group['lr'] * 0.9\n",
    "        print('Epoch:  ',i+1)\n",
    "        model.zero_grad()\n",
    "        model.train()\n",
    "        loss,y_train,Ws = model(A, node_features, train_node, train_target)\n",
    "        train_f1 = torch.mean(f1_score(torch.argmax(y_train.detach(),dim=1), train_target, num_classes=num_classes)).cpu().numpy()\n",
    "        print('Train - Loss: {}, Macro_F1: {}'.format(loss.detach().cpu().numpy(), train_f1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.eval()\n",
    "\n",
    "        # Valid\n",
    "        with torch.no_grad():\n",
    "            val_loss, y_valid,_ = model.forward(A, node_features, valid_node, valid_target)\n",
    "            val_f1 = torch.mean(f1_score(torch.argmax(y_valid,dim=1), valid_target, num_classes=num_classes)).cpu().numpy()\n",
    "            print('Valid - Loss: {}, Macro_F1: {}'.format(val_loss.detach().cpu().numpy(), val_f1))\n",
    "            test_loss, y_test,W = model.forward(A, node_features, test_node, test_target)\n",
    "            test_f1 = torch.mean(f1_score(torch.argmax(y_test,dim=1), test_target, num_classes=num_classes)).cpu().numpy()\n",
    "            print('Test - Loss: {}, Macro_F1: {}\\n'.format(test_loss.detach().cpu().numpy(), test_f1))\n",
    "        \n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_loss = val_loss.detach().cpu().numpy()\n",
    "            best_test_loss = test_loss.detach().cpu().numpy()\n",
    "            best_train_loss = loss.detach().cpu().numpy()\n",
    "            best_train_f1 = train_f1\n",
    "            best_val_f1 = val_f1\n",
    "            best_test_f1 = test_f1 \n",
    "            \n",
    "    print('---------------Best Results--------------------')\n",
    "    print('Train - Loss: {}, Macro_F1: {}'.format(best_train_loss, best_train_f1))\n",
    "    print('Valid - Loss: {}, Macro_F1: {}'.format(best_val_loss, best_val_f1))\n",
    "    print('Test - Loss: {}, Macro_F1: {}'.format(best_test_loss, best_test_f1))\n",
    "    final_f1 += best_test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
