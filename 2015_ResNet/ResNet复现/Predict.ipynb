{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet网络结构\n",
    "class BasicBlock(nn.Module): # basic残差块\n",
    "    expansion = 1 # 扩张大小\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x): # 前向传播（残差块）\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x) # 恒等映射\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module): # 瓶颈残差块\n",
    "    # width_per_group = 8, groups = 32 分组卷积Resnext架构\n",
    "    expansion = 4 # 扩张大小\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None,\n",
    "                 groups=1, width_per_group=64):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        width = int(out_channel * (width_per_group / 64.)) * groups # 深度\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width,\n",
    "                               kernel_size=1, stride=1, bias=False)  # 压缩通道squeeze channels\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        # -----------------------------------------\n",
    "        self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups,\n",
    "                               kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        # -----------------------------------------\n",
    "        self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel*self.expansion,\n",
    "                               kernel_size=1, stride=1, bias=False)  # 解压缩通道 unsqueeze channels\n",
    "        self.bn3 = nn.BatchNorm2d(out_channel*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x): # 前向传播\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x) # 恒等映射\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 block,  # 残差块类型\n",
    "                 blocks_num, # 各类型的残差块数量\n",
    "                 num_classes=1000, # 分类种类\n",
    "                 include_top=True, # 是否包含最顶层\n",
    "                 groups=1, # 分组\n",
    "                 width_per_group=64): # 分组维度\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.include_top = include_top\n",
    "        self.in_channel = 64 # 输入通道数，深度\n",
    "\n",
    "        self.groups = groups \n",
    "        self.width_per_group = width_per_group\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2,\n",
    "                               padding=3, bias=False)  # 卷积层(1)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel) # BN层, 用于各通道标准化\n",
    "        self.relu = nn.ReLU(inplace=True) # 激活函数ReLU\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) # 最大池化层\n",
    "        self.layer1 = self._make_layer(block, 64, blocks_num[0],stride=2) # 残差块（1）,共blocks_num[0]个, 3个\n",
    "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2) # 残差块（2）,共blocks_num[1]个, 4个\n",
    "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2) # 残差块（3）,共blocks_num[2]个, 6个\n",
    "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2) # 残差块（4）,共blocks_num[3]个, 3个\n",
    "        if self.include_top:\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # 自适应平均池化, output size = (1, 1)\n",
    "            self.fc = nn.Linear(512 * block.expansion, num_classes) # 线性变换\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d): # 判断该层是否为二维卷积层\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') # 进行权重初始化\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1): # 构造残差块\n",
    "        downsample = None # 是否下采样\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion: # 当维度不配时，即残差块与残块之间的连接问题\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channel * block.expansion)) # 下采样\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channel,\n",
    "                            channel,\n",
    "                            downsample=downsample,\n",
    "                            stride=stride,\n",
    "                            groups=self.groups,\n",
    "                            width_per_group=self.width_per_group))\n",
    "        self.in_channel = channel * block.expansion\n",
    "\n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(block(self.in_channel,\n",
    "                                channel,\n",
    "                                groups=self.groups,\n",
    "                                width_per_group=self.width_per_group))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.include_top:\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1) # 展平变成一维\n",
    "            x = self.fc(x) # 变成指定维度\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet34(num_classes=1000, include_top=True):\n",
    "    # https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=381x499 at 0x278E48F5520>\n",
      "tensor([[[0.1529, 0.1451, 0.1294,  ..., 0.2941, 0.3176, 0.2392],\n",
      "         [0.1451, 0.1451, 0.1373,  ..., 0.3098, 0.3333, 0.2549],\n",
      "         [0.1333, 0.1333, 0.1373,  ..., 0.2980, 0.3255, 0.2549],\n",
      "         ...,\n",
      "         [0.7255, 0.7373, 0.7294,  ..., 0.7255, 0.6314, 0.6196],\n",
      "         [0.7020, 0.7294, 0.7451,  ..., 0.6157, 0.5490, 0.5255],\n",
      "         [0.6745, 0.7176, 0.7333,  ..., 0.6745, 0.5804, 0.4235]],\n",
      "\n",
      "        [[0.2549, 0.2431, 0.2275,  ..., 0.4078, 0.4431, 0.3725],\n",
      "         [0.2471, 0.2471, 0.2353,  ..., 0.4000, 0.4353, 0.3647],\n",
      "         [0.2392, 0.2314, 0.2353,  ..., 0.3961, 0.4275, 0.3686],\n",
      "         ...,\n",
      "         [0.7569, 0.7647, 0.7569,  ..., 0.6863, 0.6000, 0.5882],\n",
      "         [0.7216, 0.7451, 0.7608,  ..., 0.5961, 0.5216, 0.4902],\n",
      "         [0.6902, 0.7294, 0.7412,  ..., 0.6627, 0.5608, 0.4000]],\n",
      "\n",
      "        [[0.3843, 0.3922, 0.3882,  ..., 0.8000, 0.8235, 0.7333],\n",
      "         [0.3765, 0.3922, 0.3922,  ..., 0.7922, 0.8275, 0.7412],\n",
      "         [0.3647, 0.3804, 0.3961,  ..., 0.7725, 0.8196, 0.7529],\n",
      "         ...,\n",
      "         [0.8118, 0.8196, 0.8196,  ..., 0.6588, 0.5373, 0.4941],\n",
      "         [0.7647, 0.7961, 0.8235,  ..., 0.5608, 0.4627, 0.4078],\n",
      "         [0.7098, 0.7725, 0.8078,  ..., 0.6549, 0.5255, 0.3176]]])\n"
     ]
    }
   ],
   "source": [
    "image_path = \"./data/test/1.JPG\"  # 导入图片\n",
    "trans = transforms.Compose([transforms.Resize((120, 120)),\n",
    "                            transforms.ToTensor()])  # 将图片缩放为跟训练集图片的大小一样 方便预测，且将图片转换为张量\n",
    "image = Image.open(image_path)  # 打开图片\n",
    "print(image)  # 输出图片 看看图片格式\n",
    "image = image.convert(\"RGB\")  # 将图片转换为RGB格式\n",
    "image = trans(image)  # 上述的缩放和转张量操作在这里实现\n",
    "print(image)  # 查看转换后的样子\n",
    "image = torch.unsqueeze(image, dim=0)  # 将图片维度扩展一维\n",
    "\n",
    "classes = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\",'……']  # 预测种类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n",
      "torch.Size([1, 1000])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # 将代码放入GPU进行训练\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "net = resnet34()\n",
    "net.load_state_dict(torch.load(\"Resnet34.pth\", map_location=device))\n",
    "net.to(device)\n",
    "net.eval()  # 关闭梯度，将模型调整为测试模式\n",
    "with torch.no_grad():  # 梯度清零\n",
    "    outputs = net(image.to(device))  # 将图片打入神经网络进行测试\n",
    "    # print(net)  # 输出模型结构\n",
    "    print(outputs.shape)  # 输出预测的张量数组\n",
    "    ans = (outputs.argmax(1)).item()  # 最大的值即为预测结果，找出最大值在数组中的序号，\n",
    "    # 对应找其在种类中的序号即可然后输出即为其种类\n",
    "    print(classes[ans])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47e86d731e077963188d400b641a1f5cee6401b89b8a1175acb1a082248e2517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
